{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The update_default_config function is deprecated and may be removed in a future version. [astroquery._astropy_init]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from astropy.time import Time\n",
    "\n",
    "from orbitize.results import Results\n",
    "from orbitize.sampler import MCMC\n",
    "from orbitize.lnlike import chi2_lnlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the posteriors from the various orbit fits\n",
    "\n",
    "nograv_results = Results()\n",
    "nograv_results.load_results('results/with_literature_astrom/chains.hdf5')\n",
    "\n",
    "onegrav_results = Results()\n",
    "onegrav_results.load_results('results/with_literature_astromwith_first_vlti_point/chains.hdf5')\n",
    "\n",
    "other_onegrav_results = Results()\n",
    "other_onegrav_results.load_results('results/with_literature_astromwith_second_vlti_point/chains.hdf5')\n",
    "\n",
    "twograv_results = Results()\n",
    "twograv_results.load_results('results/with_literature_astromwith_first_vlti_pointwith_second_vlti_point/chains.hdf5')\n",
    "\n",
    "onlygrav_results = Results()\n",
    "onlygrav_results.load_results('results/with_first_vlti_pointwith_second_vlti_point/chains.hdf5')\n",
    "\n",
    "fixed_ecc_results = Results()\n",
    "fixed_ecc_results.load_results('results/with_literature_astromwith_first_vlti_pointwith_second_vlti_point_fixed_ecc/chains.hdf5')\n",
    "\n",
    "lin_ecc_results = Results()\n",
    "lin_ecc_results.load_results('results/with_literature_astromwith_first_vlti_pointwith_second_vlti_point_linear_ecc/chains.hdf5')\n",
    "\n",
    "all_results = {\n",
    "    nograv_results: 'literature data only', \n",
    "    onegrav_results:'literature + GRAVITY epoch 1' , \n",
    "    other_onegrav_results: 'literature + GRAVITY epoch 2', \n",
    "    twograv_results: '\\\\textbf{all data (accepted fit)}',\n",
    "    onlygrav_results:'GRAVITY data only',\n",
    "    fixed_ecc_results: 'all data, ecc. fixed to 0',\n",
    "    lin_ecc_results:'all data, decreasing ecc. prior'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make MCMC convergence plots\n",
    "\n",
    "param = 'pan1'\n",
    "\n",
    "for res in all_results:\n",
    "    smas = res.post[:, res.system.param_idx[param]]\n",
    "\n",
    "    num_walkers = 1000\n",
    "    n_steps = len(smas) // num_walkers\n",
    "    chn = smas.reshape((num_walkers, n_steps))\n",
    "\n",
    "    walkers_to_plot = np.random.choice(num_walkers, size=100, replace=False)\n",
    "    plt.figure()\n",
    "    for w in walkers_to_plot:\n",
    "        plt.plot(chn[w, :], color='k', alpha=0.01)\n",
    "    plt.xlabel('step number / 100')\n",
    "    plt.ylabel(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the sma, ecc, and inc posteriors\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8,11))\n",
    "for a in ax:\n",
    "    a.set_yticks([])\n",
    "\n",
    "ax[0].set_xlabel('sma [au]')\n",
    "ax[1].set_xlabel('ecc')\n",
    "ax[2].set_xlabel('inc [deg]')\n",
    "\n",
    "plot_dict = {\n",
    "    nograv_results: {'ec': None, 'fc': 'grey', 'alpha': 0.5, 'histtype':'stepfilled'},\n",
    "    onegrav_results: {'ec': 'hotpink', 'fc': 'white', 'histtype':'step'},\n",
    "    other_onegrav_results: {'ec': 'pink', 'fc': 'white', 'histtype':'step'},\n",
    "    twograv_results: {'ec': 'purple', 'fc': 'white',  'histtype':'step'},\n",
    "    onlygrav_results: {'ec': None, 'fc': 'skyblue',  'histtype':'stepfilled', 'alpha':0.5}\n",
    "}\n",
    "\n",
    "for res, lab in zip(\n",
    "    [nograv_results, onegrav_results, other_onegrav_results, onlygrav_results, twograv_results],\n",
    "    ['lit. only', 'lit. + 1st GRAV.', 'lit. + 2nd GRAV.', 'GRAV. only', 'lit. + 2 GRAV.']\n",
    "):\n",
    "    ax[0].hist(res.post[:, res.system.param_idx['sma1']], bins=100, range=(40, 200), label=lab, **plot_dict[res], density=True)\n",
    "    ax[1].hist(res.post[:, res.system.param_idx['ecc1']], bins=100, **plot_dict[res], density=True)\n",
    "    ax[2].hist(np.degrees(res.post[:, res.system.param_idx['inc1']]), range=(70, 175), bins=100, **plot_dict[res], density=True)\n",
    "\n",
    "ax[0].legend()\n",
    "plt.savefig('results/plots/orbit_compare.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the planetary RV vs the measurement\n",
    "\n",
    "rv_epoch = twograv_results.data[twograv_results.data['quant_type'] == 'rv']['epoch'].value[0]\n",
    "\n",
    "# compute the planetary RV at the measured epoch for each posterior sample\n",
    "_, _, rv_out = twograv_results.system.compute_all_orbits(\n",
    "    twograv_results.post.T, epochs=np.array([rv_epoch])\n",
    ")\n",
    "\n",
    "rv_predictions = rv_out[0,1,:]\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    rv_predictions, bins=100, density=True, label='vals. from orbit fit', \n",
    "    histtype='step', color='purple'\n",
    ")\n",
    "\n",
    "# overplot the RV measurement and uncertainty\n",
    "rv_meas = twograv_results.data[twograv_results.data['quant_type'] == 'rv']['quant1'].value[0]\n",
    "rv_unc = twograv_results.data[twograv_results.data['quant_type'] == 'rv']['quant1_err'].value[0]\n",
    "\n",
    "rv2plot = np.linspace(-2, 40, int(1e3))\n",
    "\n",
    "def norm(x, mu, sig):\n",
    "    return 1 / (sig * np.sqrt(2*np.pi)) * np.exp(-0.5 * ((x - mu)/sig)**2)\n",
    "\n",
    "plt.plot(rv2plot, 10 * norm(rv2plot, rv_meas, rv_unc), label='HDS meas.', color='k', ls='--')\n",
    "plt.yticks([])\n",
    "plt.xlabel('RV$_{{\\\\rm pl}}$ - RV$_{{*}}$ [km s$^{{-1}}$]')\n",
    "plt.xlim(-2,40)\n",
    "\n",
    "onesig_rvrange = np.linspace(rv_meas - rv_unc, rv_meas + rv_unc, int(1e3))\n",
    "plt.fill_between(\n",
    "    onesig_rvrange, np.zeros(int(1e3)), 10 * norm(onesig_rvrange, rv_meas, rv_unc),\n",
    "    color='k', alpha=0.1, ec=None\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('results/plots/rv_meas.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the eccentricity posteriors using different priors\n",
    "\n",
    "plt.figure()\n",
    "colors=['hotpink', 'purple']\n",
    "for i, res in enumerate([lin_ecc_results, twograv_results]):\n",
    "    plt.hist(res.post[:, res.system.param_idx['ecc1']], bins=50, color=colors[i], alpha=0.3, density=True)\n",
    "\n",
    "# overplot the prior in each case\n",
    "m = -2.18\n",
    "b = 2.01\n",
    "xplot = np.array([0, -b/m, 1])\n",
    "norm = -0.5*b**2/m\n",
    "print(norm)\n",
    "yplot = (m * xplot + b) / norm\n",
    "yplot[-1] = 0\n",
    "\n",
    "plt.plot(xplot, yplot, color=colors[0], ls='--', label='linear')\n",
    "plt.plot(xplot, np.ones(len(xplot)), color=colors[1], ls='-.', label='uniform')\n",
    "plt.xlim(0,1)\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xlabel('ecc.')\n",
    "plt.savefig('results/plots/ecc_compare.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the log-likelihoods for the fixed eccentricity posterior vs the accepted one\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "labels = ['Fixed ecc.','Accepted']\n",
    "colors = ['hotpink','purple']\n",
    "for i, res in enumerate([fixed_ecc_results, twograv_results]):\n",
    "    plt.hist(res.lnlike, bins=50, alpha=0.3, density=True, label=labels[i], color=colors[i], range=(-30,-16))\n",
    "    print(res.post[:,1][np.argmax(res.lnlike)])\n",
    "    # plt.hist(res.lnlike[res.post[:,1] > 0.4], density=True, alpha=0.5,bins=50, range=(-30,-16))\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.xlim(-30,-16)\n",
    "plt.xlabel('log(L)')\n",
    "plt.savefig('results/plots/ecc_lnlike_compare.png', dpi=250)\n",
    "\n",
    "plt.figure()\n",
    "for i, res in enumerate([fixed_ecc_results, twograv_results]):\n",
    "    ecc_post = res.post[:,1]\n",
    "    plt.scatter(ecc_post, -1*res.lnlike)\n",
    "    print(np.max(res.lnlike))\n",
    "plt.ylim(16.5, 17.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "plt.figure()\n",
    "for e in np.linspace(0, .8, 20):\n",
    "    e_sampler = MCMC(twograv_results.system)\n",
    "\n",
    "    def neg_lnlike_func(x):\n",
    "        sma, inc, aop, pan, tau = x\n",
    "        if sma < 0 or inc < 0 or inc > np.pi or pan < 0 or pan > np.pi or tau < 0 or tau > 1:\n",
    "            return np.inf\n",
    "        return -1* e_sampler._logl([sma, e, inc, aop, pan, tau, 9.28, 1.96])\n",
    "\n",
    "    p0 = [70, np.radians(110), np.radians(200), np.radians(160), 0.5]\n",
    "    res = minimize(neg_lnlike_func, p0, method='Nelder-Mead', options={'maxiter':int(1e9), 'maxfev':int(1e10)})\n",
    "    \n",
    "    best_lnlike = res.fun\n",
    "    print('Best lnlike for e={:.3f}: {:.3f}'.format(e, best_lnlike))\n",
    "\n",
    "    plt.scatter([e], [-best_lnlike], color='rebeccapurple')\n",
    "\n",
    "plt.xlabel('ecc')\n",
    "plt.ylabel('log$\\\\mathcal{{L}}_{{\\\\mathrm{{max}}}}$')\n",
    "plt.ylim(-17.5, -16.9)\n",
    "plt.savefig('results/plots/ecc_lnlike.png', dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.34903312428057 -106.30990861437108 -108.31444753707115\n"
     ]
    }
   ],
   "source": [
    "# compute AIC & WAIC for each of the three various-eccentricity-prior fits\n",
    "# ref: http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf\n",
    "# I like the WAIC because it is Bayesian and ya girl is v Bayesian. I'll include a pedantic rant in the paper about it.\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def calc_lnlikes(system, params):\n",
    "    model, jitter = system.compute_model(params)\n",
    "\n",
    "    # fold data/errors to match model output shape. In particualr, quant1/quant2 are interleaved\n",
    "    data = np.array([system.data_table['quant1'], system.data_table['quant2']]).T\n",
    "\n",
    "    # errors below required for lnlike function below\n",
    "    errs = np.array([system.data_table['quant1_err'],\n",
    "                        system.data_table['quant2_err']]).T\n",
    "\n",
    "    corrs = system.data_table['quant12_corr']\n",
    "\n",
    "    # grab all seppa indices\n",
    "    seppa_indices = system.all_seppa\n",
    "\n",
    "    # compute lnlike\n",
    "    lnlikes = chi2_lnlike(data, errs, corrs, model, jitter, seppa_indices)\n",
    "\n",
    "    return lnlikes\n",
    "\n",
    "def waic(results, N=100000):\n",
    "    # lots of this code stolen from pymc3 which has an excellent stats module\n",
    "\n",
    "    # compute log-pointwise predictive density for in-sample data\n",
    "    random_idx = np.random.choice(np.arange(len(results.post)), size=N)\n",
    "    lnlikes = calc_lnlikes(results.system, results.post[random_idx,].T)\n",
    "\n",
    "    # for RVs, second dimension of a data point (x1, x2) is nan\n",
    "    lnlikes_i = lnlikes[:,0,:] + np.nan_to_num(lnlikes[:,1,:])\n",
    "\n",
    "    # this is the log pointwise predictive density of each data point (i.e. the average likelihood of each posterior sample)\n",
    "    lppd_i = logsumexp(lnlikes_i, axis=1, b=1.0 / lnlikes.shape[0]) # eq 5 of Gelman paper linked above\n",
    "    lppd = np.sum(lppd_i)\n",
    "    p_waic = np.sum(np.var(lnlikes_i, axis=1))\n",
    "\n",
    "    # draw S samples from posterior\n",
    "    # compute log-likelihood of one data point across all models, and add together, then divide by S and add across all models\n",
    "    # second term computes variance of log-chi2 probability for each data point then adds over data points\n",
    "    # multiply by -2 to put on same scale as AIC\n",
    "\n",
    "    return -2 * (lppd - p_waic)\n",
    "    \n",
    "e_uniform_waic = waic(twograv_results)\n",
    "e_dec_waic = waic(lin_ecc_results)\n",
    "e_fixed_waic = waic(fixed_ecc_results)\n",
    "print(e_uniform_waic, e_dec_waic, e_fixed_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an overleaf table of all of the fit results\n",
    "\n",
    "def format_post(results_obj, el_label, n_decimals=1, degrees=False, dont_print_circ_toggle=False):\n",
    "    quants = np.quantile(results_obj.post[:, results_obj.system.param_idx[el_label]], [.16, .50, .84])\n",
    "\n",
    "    if dont_print_circ_toggle:\n",
    "        return '--'\n",
    "\n",
    "    if degrees:\n",
    "        quants = np.degrees(quants)\n",
    "\n",
    "    med = quants[1]\n",
    "    up_lim = quants[2] - quants[1]\n",
    "    lo_lim = quants[1] - quants[0]\n",
    "\n",
    "    if up_lim == lo_lim:\n",
    "        if el_label == 'ecc1':\n",
    "            return '=0'\n",
    "\n",
    "    \n",
    "    if np.abs(up_lim - lo_lim) <= 1/(10*n_decimals):\n",
    "        return '${:.{prec}f}\\\\pm{{{:.{prec}f}}}$'.format(med, up_lim, prec=n_decimals)\n",
    "\n",
    "    return '${:.{prec}f}^{{+{:.{prec}f}}}_{{-{:.{prec}f}}}$'.format(\n",
    "        med, up_lim, lo_lim, prec=n_decimals\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "for res in all_results.keys():\n",
    "\n",
    "    dont_print_circ_toggle = False\n",
    "    if all_results[res] == 'all data, ecc. fixed to 0':\n",
    "        dont_print_circ_toggle = True\n",
    "\n",
    "    print('{} & {} & {} & {} & {} & {} & {} & {} & {} \\\\\\\\'.format(\n",
    "        all_results[res],\n",
    "        format_post(res, 'sma1', n_decimals=1),\n",
    "        format_post(res, 'ecc1', n_decimals=2),\n",
    "        format_post(res, 'inc1', n_decimals=1, degrees=True),\n",
    "        format_post(res, 'aop1', n_decimals=1, degrees=True, dont_print_circ_toggle=dont_print_circ_toggle),\n",
    "        format_post(res, 'pan1', n_decimals=1, degrees=True),\n",
    "        format_post(res, 'tau1', n_decimals=2, dont_print_circ_toggle=dont_print_circ_toggle),\n",
    "        format_post(res, 'plx', n_decimals=2),\n",
    "        format_post(res, 'mtot', n_decimals=2)\n",
    "    )\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the accepted orbit fit posteriors forward in time; plot deltaRA & deltaDec by eccentricity\n",
    "date = {'year':2050, 'month':5,'day':15}\n",
    "epoch = Time(date, format='ymdhms')\n",
    "\n",
    "n_to_plot = 3000\n",
    "indx = np.random.choice(len(twograv_results.post), size=n_to_plot)\n",
    "\n",
    "raoff, deoff, _ = twograv_results.system.compute_all_orbits(twograv_results.post[indx,:].T, epochs=np.array([epoch.mjd]))\n",
    "raoff_pl = raoff[:,1,:][0]\n",
    "deoff_pl = deoff[:,1,:][0]\n",
    "\n",
    "\n",
    "print(twograv_results.system.tau_ref_epoch)\n",
    "fig, ax = plt.subplots()\n",
    "eccentricities = twograv_results.post[indx,:][:,1]\n",
    "plt.scatter(raoff_pl, deoff_pl, color=cm.rainbow(eccentricities), alpha=0.75, s=2)\n",
    "\n",
    "\n",
    "raoff, deoff, _ = fixed_ecc_results.system.compute_all_orbits(fixed_ecc_results.post[indx,:].T, epochs=np.array([epoch.mjd]))\n",
    "raoff_pl = raoff[:,1,:][0]\n",
    "deoff_pl = deoff[:,1,:][0]\n",
    "\n",
    "eccentricities = np.zeros(n_to_plot)\n",
    "plt.scatter(raoff_pl, deoff_pl, color=cm.rainbow(eccentricities), alpha=0.5, s=2)\n",
    "plt.ylabel('$\\Delta$Dec.')\n",
    "plt.xlabel('$\\Delta$R.A.')\n",
    "ax.set_xlim((ax.get_xlim()[1], ax.get_xlim()[0]))\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax_cbar = plt.colorbar()\n",
    "ax_cbar.set_label('eccentricity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/plots/orbit_predict{}-{}.png'.format(date['month'], date['year']), dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "154d87402400beea08d12f3196cbb2d5eec809167b50e0856af6d5a1d0d51a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
